{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "903b72ba-07b8-4f17-a4a3-b062aac2d57c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The history saving thread hit an unexpected error (OperationalError('attempt to write a readonly database')).History will not be written to the database.\n",
      "Result for f1 (Test Case 1): (0.010737418240000003, 0.010737418240000003)\n",
      "Result for f1 (Test Case 2): (-0.13261955589475316, 0.13261955589475316)\n",
      "Result for f2 (Test Case 1): (0.0, 2.0000009002751056)\n",
      "Result for f2 (Test Case 2): (0.0, 2.0000009002751056)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "def gradient_descent(x0, y0, f, grad_f, alpha, num_iterations):\n",
    "    \"\"\"\n",
    "    Perform gradient descent optimization.\n",
    "    \n",
    "    Parameters:\n",
    "    x0, y0: Initial point for the descent.\n",
    "    f: A function of two variables.\n",
    "    grad_f: The gradient of f.\n",
    "    alpha: Learning rate.\n",
    "    num_iterations: Number of iterations to perform.\n",
    "    \n",
    "    Returns:\n",
    "    (x, y): The coordinates of the final point after gradient descent.\n",
    "    \"\"\"\n",
    "    x, y = x0, y0  # Initialize x and y with the initial point\n",
    "    for i in range(num_iterations):\n",
    "        # Obtain the gradient of f at (x, y)\n",
    "        grad_x, grad_y = grad_f(x, y)\n",
    "        # Update x and y by taking a step in the opposite direction of the gradient\n",
    "        x -= alpha * grad_x\n",
    "        y -= alpha * grad_y\n",
    "    return x, y\n",
    "\n",
    "# Function f1(x, y) = x^2 + y^2 and its gradient\n",
    "def fun_1(x, y):\n",
    "    return x**2 + y**2\n",
    "\n",
    "def grad_f_1(x, y):\n",
    "    grad_x = 2 * x\n",
    "    grad_y = 2 * y\n",
    "    return grad_x, grad_y\n",
    "\n",
    "# Test cases for f1\n",
    "x0_1, y0_1 = 0.1, 0.1\n",
    "alpha_1 = 0.1\n",
    "max_iterations_1 = 10\n",
    "result_1 = gradient_descent(x0_1, y0_1, fun_1, grad_f_1, alpha_1, max_iterations_1)\n",
    "print(\"Result for f1 (Test Case 1):\", result_1)\n",
    "\n",
    "x0_2, y0_2 = -1, 1\n",
    "alpha_2 = 0.01\n",
    "max_iterations_2 = 100\n",
    "result_2 = gradient_descent(x0_2, y0_2, fun_1, grad_f_1, alpha_2, max_iterations_2)\n",
    "print(\"Result for f1 (Test Case 2):\", result_2)\n",
    "\n",
    "# Function f2(x, y) = 1 - exp(-x^2 - (y - 2)^2) - 2 * exp(-x^2 - (y + 2)^2) and its gradient\n",
    "def fun_2(x, y):\n",
    "    return 1 - np.exp(-x**2 - (y - 2)**2) - 2 * np.exp(-x**2 - (y + 2)**2)\n",
    "\n",
    "def grad_f_2(x, y):\n",
    "    grad_x = 2 * x * (np.exp(-x**2 - (y - 2)**2) + 2 * np.exp(-x**2 - (y + 2)**2))\n",
    "    grad_y = 2 * (y - 2) * np.exp(-x**2 - (y - 2)**2) - 4 * (y + 2) * np.exp(-x**2 - (y + 2)**2)\n",
    "    return grad_x, grad_y\n",
    "\n",
    "# Test cases for f2\n",
    "x0_3, y0_3 = 0, 1\n",
    "alpha_3 = 0.01\n",
    "max_iterations_3 = 10000\n",
    "result_3 = gradient_descent(x0_3, y0_3, fun_2, grad_f_2, alpha_3, max_iterations_3)\n",
    "print(\"Result for f2 (Test Case 1):\", result_3)\n",
    "\n",
    "x0_4, y0_4 = 0, -1\n",
    "alpha_4 = 0.01\n",
    "max_iterations_4 = 10000\n",
    "result_4 = gradient_descent(x0_4, y0_4, fun_2, grad_f_2, alpha_4, max_iterations_4)\n",
    "print(\"Result for f2 (Test Case 2):\", result_4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00a8f0aa-7ce3-4f19-9d08-9ef2a40814a5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
